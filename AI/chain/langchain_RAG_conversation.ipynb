{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "langchain_RAG\n"
     ]
    }
   ],
   "source": [
    "from chain_logging import langsmith\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "langsmith(\"langchain_RAG\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대화 내용을 기억하는 기능을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing vectorstore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\ssafy\\자율프로젝트\\S11P31S102\\AI\\chain\\vectorstore_manager.py:42: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from vectorstore_manager import (\n",
    "    load_vectorstore,\n",
    "    create_vectorstore,\n",
    "    create_conversaion_memory,\n",
    ")\n",
    "from config import PDF_PATH, VECTORSTORE_PATH, MODEL_PATH, LOCAL_MODEL_PATH, MODEL_NAME\n",
    "from utils import get_embeddings, format_docs_with_print, create_prompt\n",
    "from load_model import load_model, create_model\n",
    "\n",
    "# Load or create vectorstore\n",
    "if os.path.exists(VECTORSTORE_PATH):\n",
    "    print(\"Loading existing vectorstore...\")\n",
    "    embeddings = get_embeddings()\n",
    "    loaded_vectorstore = load_vectorstore(VECTORSTORE_PATH, embeddings)\n",
    "else:\n",
    "    print(\"Vectorstore not found. Creating a new one...\")\n",
    "    embeddings = get_embeddings()\n",
    "    loaded_vectorstore = create_vectorstore(PDF_PATH, VECTORSTORE_PATH, embeddings)\n",
    "\n",
    "# 대화를 기억할 메모리 객체 생성\n",
    "memory = create_conversaion_memory(\"chat_history\", \"answer\")\n",
    "\n",
    "# 단계 5: 리트리버 생성\n",
    "k = 2\n",
    "retriever = loaded_vectorstore.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "# 단계 6: 프롬프트 생성\n",
    "prompt = create_prompt()\n",
    "\n",
    "# 단계7: 언어모델 생성\n",
    "# Ollama 모델을 불러옵니다.\n",
    "llm = ChatOllama(model=MODEL_PATH, temperature=0)\n",
    "\n",
    "# if os.path.exists(LOCAL_MODEL_PATH):\n",
    "#     print(\"Loading existing Local Model...\")\n",
    "#     llm = load_model(LOCAL_MODEL_PATH)\n",
    "# else:\n",
    "#     print(\"Local Model not found. Creating a new one...\")\n",
    "#     create_model(MODEL_NAME,LOCAL_MODEL_PATH)\n",
    "#     llm = load_model(LOCAL_MODEL_PATH)\n",
    "\n",
    "\n",
    "# 단계 8: 체인 생성\n",
    "# 단계 8: 체인 생성\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs_with_print,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"chat_history\": lambda x: memory.load_memory_variables({})[\"chat_history\"],\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HUMAN]\n",
      "아까 물어본 질문을 다시 알려주세요\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== Retrieved Documents ===\n",
      "\n",
      "Document 1:\n",
      "..\\kisa_pdf\\3_04_감사규칙(230605).pdf |  page: 20\n",
      "[별지제8호]<개정2013.5.8>\n",
      "질문서\n",
      "제목:\n",
      "질문사항 답변사항\n",
      "홍길동귀하 홍길동귀하\n",
      "다음사항에대하여 20년00월00일까지\n",
      "답변하여주시기바랍니다 .다음과같이답변합니다 .\n",
      "20년00월00일\n",
      "소속:\n",
      "20년00월00일 직급 (직책 ):\n",
      "감사실장 :  성명:홍길동\n",
      "--------------------------------------------------\n",
      "\n",
      "Document 2:\n",
      "..\\kisa_pdf\\4_46_118상담센터 상담사 보호에 관한 업무 운영지침(221223).pdf |  page: 8\n",
      "3.민원요지불명\n",
      "구분내용 처리프로세스 세부응대프로세스\n",
      "1단계민원응대및\n",
      "경고후종료①1차경고\n",
      "②2차경고\n",
      "③3차경고및IVR응대<1차경고>\n",
      "“선생님 ,문의하실내용을말씀해주세요 .그렇지않으면내용이 \n",
      "파악되지않아더이상상담진행이어렵습니다 .”\n",
      "<2차경고>\n",
      "“선생님 ,문의하실내용을말씀해주세요 .그렇지않으면내용이 \n",
      "파악되지않아더이상상담진행이어렵습니다 .”\n",
      "<3차경고>\n",
      "“문의내용이파악되지않아상담이불가합니다 .통화종료하\n",
      "겠습니다 .”\n",
      "→멘트구사후IVR전환\n",
      "<IVR경고멘트자동송출 >\n",
      "문의내용이파악되지않아상담이불가합니다 .상담사의권익\n",
      "보호를위하여 ,선생님의상담이 7일간제한됨을알려드립니다 .\n",
      "2단계악성민원등록①상담사상담후팀장보고\n",
      "②팀장내용확인후상담APP\n",
      "강성민원등록(민원요지불명 )강성민원등록시,동일번호 7일간이용정지\n",
      "3-1단계이용정지 IVR연결불가멘트송출<IVR연결불가멘트자동송출 >\n",
      "상담사의권익보호를위하여 ,선생님의상담이제한됨을알려\n",
      "드립니다 .\n",
      "3-2단계정지해제이용정지 8일차해제이용정지 8일차해제\n",
      "※재발시반복이용정지\n",
      "4.반복‧\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Anser: \n",
      "\n",
      "홍길동 귀하, 아까 물어보신 질문은 유류비 청구와 연차 사용에 대한 것입니다."
     ]
    }
   ],
   "source": [
    "from chain_output_stream import stream_response\n",
    "\n",
    "# 단계 8: 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
    "# question = \"연차는 어떻게 사용할 수 있나요?\"\n",
    "# question = \"유류비 청구는 어떻게 할 수 있나요? 제가 3박 4일로 부산에 갔다오는데 비용은 대충 어떻게 계산하죠?\"\n",
    "question = \"아까 물어본 질문을 다시 알려주세요\"\n",
    "\n",
    "response = rag_chain.stream(question)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"[HUMAN]\\n{question}\\n\")\n",
    "print(\"===\" * 20)\n",
    "answer = stream_response(response, return_output=True)\n",
    "\n",
    "# 메모리에 대화 내용을 저장\n",
    "memory.save_context({\"question\": question}, {\"answer\": answer})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
